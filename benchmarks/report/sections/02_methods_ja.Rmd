# 手法

本章では、このベンチマークで評価される5つの因果推論手法について説明する。各手法について、理論的基礎、重要な仮定、およびcfomicsパッケージでの実装詳細を概説する。

## 記法と設定

$i = 1, \ldots, n$ について観測データ $(Y_i, T_i, X_i)$ を考える。ここで：

- $Y_i \in \mathbb{R}$ は観測されたアウトカム
- $T_i \in \{0, 1\}$ は二値の処置指標
- $X_i \in \mathbb{R}^p$ は $p$ 次元の共変量ベクトル

潜在アウトカムの枠組みの下で、$Y_i(1)$ と $Y_i(0)$ をそれぞれ処置下と対照下の潜在アウトカムとする。観測されたアウトカムは $Y_i = T_i Y_i(1) + (1-T_i) Y_i(0)$ である。

**平均処置効果（ATE）** は以下のように定義される：
$$\tau = \mathbb{E}[Y(1) - Y(0)]$$

個体 $i$ の**個体処置効果（ITE）** は：
$$\tau_i = Y_i(1) - Y_i(0)$$

標準的な因果仮定の下で作業を行う：

1. **SUTVA**：$Y_i = Y_i(T_i)$（個体間の干渉なし）
2. **一貫性**：観測されたアウトカムは受けた処置に対応する潜在アウトカムと等しい
3. **無交絡性**：$\{Y(0), Y(1)\} \perp\!\!\!\perp T \mid X$
4. **オーバーラップ（陽性）**：すべての $X$ について $0 < P(T=1 \mid X) < 1$

## G-formula（アウトカム回帰）

### 理論的基礎

G-formula は標準化またはアウトカム回帰としても知られ、条件付きアウトカム平均をモデル化し共変量分布上で積分することでATEを推定する：

$$\hat{\tau}_{GF} = \frac{1}{n}\sum_{i=1}^n \left[\hat{\mu}_1(X_i) - \hat{\mu}_0(X_i)\right]$$

ここで $\hat{\mu}_t(x) = \mathbb{E}[Y \mid T=t, X=x]$ は推定された条件付き平均である。

### 高次元への適応

高次元では、標準的な回帰は失敗する。我々の実装では、$\mu_t(x)$ の推定に正則化回帰（Elastic Net）を使用する：

$$\hat{\mu}_t = \arg\min_\mu \sum_{i:T_i=t} (Y_i - \mu(X_i))^2 + \lambda \left(\alpha \|\mu\|_1 + (1-\alpha)\|\mu\|_2^2\right)$$

### 主要な特性

- **強み**：シンプル、解釈可能、アウトカムモデルが正しく指定されている場合に効率的
- **限界**：アウトカムモデルの誤指定に敏感；交絡因子に対する原理的な変数選択がない

### 実装

```r
cf_fit(formula, data, method = "gformula")
```

$\lambda$ の選択に交差検証を用いた `glmnet` を使用する。

## HDML（高次元機械学習 / Double ML）

### 理論的基礎

HDML は Chernozhukov et al. (2018) の二重/脱バイアス機械学習フレームワークを実装する。重要な洞察は、柔軟な機械学習手法を使用しながら過適合バイアスを回避するためにクロスフィッティングを使用することである。

推定量はモーメント条件を解く：
$$\mathbb{E}\left[\psi(Y, T, X; \tau, \eta_0)\right] = 0$$

ここで $\psi$ は二重頑健影響関数である：
$$\psi = \left(\frac{T}{\pi(X)} - \frac{1-T}{1-\pi(X)}\right)(Y - \mu_T(X)) + \mu_1(X) - \mu_0(X) - \tau$$

そして $\eta_0 = (\mu_0, \mu_1, \pi)$ はクロスフィッティングにより推定されるニューサンスパラメータである。

### クロスフィッティング手順

1. データを $K$ 個のフォールドに分割
2. 各フォールド $k$ について：
   - フォールド $k$ 以外のすべてのデータでニューサンスモデル $(\hat{\mu}_0^{-k}, \hat{\mu}_1^{-k}, \hat{\pi}^{-k})$ を学習
   - フォールド $k$ で予測
3. すべての予測を使用してモーメント条件を解く

### 主要な特性

- **強み**：二重頑健（アウトカムまたは傾向モデルのいずれかが正しければ一致）；収束率に寛容（ニューサンスパラメータはより遅い収束率でも可）
- **限界**：ML手法の慎重なチューニングが必要；計算集約的

### 実装

```r
cf_fit(formula, data, method = "hdml")
```

ニューサンス推定にランダムフォレスト、勾配ブースティング、Elastic Netのアンサンブルを使用する。

## HDPS（高次元傾向スコア）

### 理論的基礎

Schneeweiss et al. (2009) の高次元傾向スコア（HDPS）手法は、データ駆動の共変量優先順位付けにより傾向スコア手法を高次元設定に適応させる。

ATEは逆確率重み付けにより推定される：
$$\hat{\tau}_{HDPS} = \frac{1}{n}\sum_{i=1}^n \frac{T_i Y_i}{\hat{\pi}(X_i)} - \frac{1}{n}\sum_{i=1}^n \frac{(1-T_i) Y_i}{1-\hat{\pi}(X_i)}$$

ここで $\hat{\pi}(x)$ は選択された共変量サブセットを使用して推定された傾向スコアである。

### 共変量優先順位付けアルゴリズム

1. **再コード化**：連続共変量から二値指標を作成
2. **有病率フィルタリング**：被験者の5%未満に現れる共変量を削除
3. **バイアスランキング**：交絡の可能性によって共変量をランク付け（Brossバイアス公式）
4. **選択**：傾向モデル用に上位 $k$ 個の共変量を選択

### 主要な特性

- **強み**：解釈可能な選択プロセス；多くの二値指標（例：医療保険請求データ）で良好
- **限界**：傾向モデルのみに依存；オーバーラップ違反に敏感；二値共変量向けに設計

### 実装

```r
cf_fit(formula, data, method = "hdps")
```

設定可能な選択パラメータを備えた完全なHDPSアルゴリズムを実装する。

## BCF（ベイズ因果フォレスト）

### 理論的基礎

ベイズ因果フォレスト（Hahn et al., 2020）は、予後関数と処置効果関数を分離することでBART（ベイズ加法回帰木）を因果推論に拡張する：

$$Y_i = f(X_i) + \tau(X_i) T_i + \epsilon_i$$

ここで：
- $f(X_i)$ は予後効果（ベースラインリスク）を捉える
- $\tau(X_i)$ は異質的処置効果を捉える

$f$ と $\tau$ の両方がBARTの事前分布を使用してモデル化されるが、異なる正則化を持つ：

- $f$ は複雑なベースライン関係を捉えるために標準的なBART事前分布を使用
- $\tau$ は均質な効果に向けて収縮するより正則化された事前分布を使用

### 傾向スコアの統合

BCFは推定された傾向スコア $\hat{\pi}(X_i)$ を $f$ の共変量として組み込み、これにより：
- 交絡に対する標的化された正則化を提供
- RIC（正則化誘発交絡）下での性能を向上

### 主要な特性

- **強み**：優れた不確実性定量化；異質性を自然に扱う；モデル誤指定に対して頑健
- **限界**：計算コストが高い；MCMCの収束を監視する必要がある

### 実装

```r
cf_fit(formula, data, method = "bcf")
```

MCMCサンプリングを備えた `bcf` Rパッケージを使用する。デフォルト：バーンイン1000回、事後サンプル2000回。

## TMLE（標的最尤推定）

### 理論的基礎

TMLE（van der Laan & Rose, 2011）は、初期のアウトカム回帰と標的化ステップを組み合わせて最適なバイアス・分散トレードオフを保証するセミパラメトリック効率的推定量である。

### アルゴリズム

1. **初期推定**：アウトカムモデル $\hat{\mu}_0^{(0)}(X)$ と傾向モデル $\hat{\pi}(X)$ を適合
2. **標的化**：以下を適合して $\hat{\mu}$ を更新：
   $$\text{logit}(\hat{\mu}^{(1)}) = \text{logit}(\hat{\mu}^{(0)}) + \epsilon \cdot H$$
   ここで $H = T/\hat{\pi}(X) - (1-T)/(1-\hat{\pi}(X))$ はclever covariate
3. **代入**：標的化された予測を使用してATEを計算：
   $$\hat{\tau}_{TMLE} = \frac{1}{n}\sum_i \hat{\mu}_1^{(1)}(X_i) - \hat{\mu}_0^{(1)}(X_i)$$

### 主要な特性

- **強み**：二重頑健；セミパラメトリック効率的；パラメータ境界を尊重；妥当な推論
- **限界**：慎重な実装が必要；極端な傾向スコアに敏感な場合がある

### Super Learnerとの統合

我々の実装では、初期推定にSuper Learner（ML手法のアンサンブル）を使用する：

```r
cf_fit(formula, data, method = "tmle")
```

交差検証されたSuper Learnerライブラリを備えた `tmle` Rパッケージを使用する。

## 手法比較の要約

```{r method-comparison-table, echo=FALSE}
method_table <- data.frame(
  Method = c("G-formula", "HDML", "HDPS", "BCF", "TMLE"),
  `Doubly Robust` = c("No", "Yes", "No", "No*", "Yes"),
  `Uncertainty` = c("Bootstrap", "Analytic", "Bootstrap", "Bayesian", "Influence curve"),
  `Heterogeneity` = c("Limited", "Limited", "No", "Native", "Limited"),
  `Computation` = c("Fast", "Moderate", "Moderate", "Slow", "Moderate"),
  check.names = FALSE
)

# Japanese column names for display
colnames(method_table) <- c("手法", "二重頑健", "不確実性", "異質性", "計算速度")

if (requireNamespace("kableExtra", quietly = TRUE)) {
  kableExtra::kbl(method_table, booktabs = TRUE,
                  caption = "手法特性の要約") |>
    kableExtra::kable_styling(latex_options = c("hold_position"))
} else {
  knitr::kable(method_table, caption = "手法特性の要約")
}
```

*注：BCFは傾向スコアを組み込むが、古典的な意味で二重頑健ではない。*
