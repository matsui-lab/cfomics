# Discussion

This section interprets the benchmark results, provides method selection guidelines, and discusses limitations of this evaluation.

## Key Findings

### Finding 1: No Universally Best Method

```{r no-universal-best, echo=FALSE}
if (data_available && !is.null(friedman_result)) {
  if (friedman_result$p_value < 0.05) {
    cat("The Friedman test indicates significant differences between methods (p < 0.05), confirming that method choice matters. However, the ranking varies across scenarios, suggesting that the optimal method depends on the specific data characteristics and challenges.\n")
  } else {
    cat("The Friedman test does not detect significant differences between methods at the 0.05 level. This may indicate that for the scenarios tested, method differences are smaller than the between-replication variance.\n")
  }
} else {
  cat("Our benchmark reveals that no single method dominates across all scenarios. The relative performance of methods depends critically on:\n\n")
  cat("- The dimensionality of the covariate space\n")
  cat("- The presence and form of treatment effect heterogeneity\n")
  cat("- The degree of overlap between treatment groups\n")
  cat("- The complexity of confounding relationships\n")
}
```

### Finding 2: Baseline Performance Hierarchy

Under ideal conditions (S1: linear relationships, good overlap, all assumptions satisfied), we generally expect:

1. **TMLE and HDML** should perform well due to their doubly-robust properties
2. **G-formula** should be efficient when the outcome model is correctly specified
3. **BCF** should provide good uncertainty quantification with slight conservatism
4. **HDPS** may underperform with continuous covariates (designed for binary indicators)

### Finding 3: Robustness to Model Misspecification

In scenarios with nonlinear confounding (S5):

- **Tree-based methods (BCF)** should adapt well to nonlinear patterns without explicit specification
- **Doubly-robust methods (TMLE, HDML)** provide protection when either the outcome or propensity model is correct
- **Single-model methods (G-formula)** are vulnerable to misspecification

### Finding 4: Handling of Weak Overlap

The weak overlap scenarios (S7) reveal fundamental differences in method philosophy:

- **Propensity-based methods** suffer from extreme weights when overlap is poor
- **Outcome regression** can extrapolate but may be unstable
- **BCF's propensity score integration** provides targeted regularization

### Finding 5: Heterogeneous Treatment Effects

For scenarios with heterogeneous effects (S3, S4):

- **BCF** is specifically designed to estimate $\tau(X)$ and should provide the best ITE estimation
- **Other methods** target the ATE and may not accurately capture individual-level variation

## Method Selection Guidelines

Based on the benchmark results, we provide the following guidelines for method selection:

### When to Use G-formula

**Recommended when:**
- You have strong prior knowledge that the outcome model is approximately linear
- Sample size is large relative to the number of covariates
- Primary interest is in the ATE (not individual effects)
- Computational efficiency is important

**Avoid when:**
- Complex nonlinear relationships are expected
- Overlap is poor

### When to Use HDML

**Recommended when:**
- Model misspecification is a concern
- You want doubly-robust protection
- Multiple ML algorithms should be considered
- Standard errors from influence functions are desired

**Avoid when:**
- Sample size is very small (cross-fitting becomes unstable)
- Computational resources are limited

### When to Use HDPS

**Recommended when:**
- Data consists primarily of binary indicators (e.g., healthcare claims)
- Interpretable covariate selection is desired
- Regulatory requirements favor propensity-based methods

**Avoid when:**
- Covariates are primarily continuous
- Overlap is poor (IPW weights become extreme)

### When to Use BCF

**Recommended when:**
- Heterogeneous treatment effects are of primary interest
- Full posterior distributions for uncertainty are desired
- Nonlinear relationships are expected
- Moderate computational time is acceptable

**Avoid when:**
- Only the ATE is needed and speed is critical
- Very large datasets (MCMC scaling)

### When to Use TMLE

**Recommended when:**
- Semiparametric efficiency is desired
- Valid inference with Super Learner is needed
- The outcome is bounded (TMLE respects bounds)
- Doubly-robust protection is important

**Avoid when:**
- Extreme propensity scores cannot be handled (truncation may help)
- Very simple settings where G-formula suffices

## Decision Flowchart

```
Is heterogeneous effect estimation important?
├── Yes → BCF
└── No → Are you concerned about model misspecification?
         ├── Yes → Are covariates primarily binary?
         │         ├── Yes → HDPS
         │         └── No → TMLE or HDML
         └── No → Is computational speed critical?
                  ├── Yes → G-formula
                  └── No → TMLE
```

## Practical Recommendations

### 1. Always Check Overlap

Before applying any method, diagnose propensity score overlap:

```r
# Check propensity score distribution
ps <- predict(glm(T ~ ., data = df, family = binomial), type = "response")
summary(ps)
hist(ps[df$T == 1], col = rgb(1,0,0,0.5), main = "Propensity Score Overlap")
hist(ps[df$T == 0], col = rgb(0,0,1,0.5), add = TRUE)
```

If overlap is poor, consider:
- Trimming extreme propensity scores
- Using outcome regression rather than IPW
- Restricting analysis to the region of overlap

### 2. Conduct Sensitivity Analysis

Given the fundamental unverifiability of unconfoundedness:

- Report results from multiple methods
- Conduct formal sensitivity analysis (e.g., E-value, Rosenbaum bounds)
- Be transparent about assumptions

### 3. Validate on Positive Controls

When possible, validate methods on:
- Semi-synthetic data (real covariates, simulated treatment/outcome)
- Known causal effects from RCTs
- Negative control outcomes

### 4. Consider Ensemble Approaches

Rather than selecting a single method, consider:
- Reporting estimates from multiple methods
- Using model averaging weighted by cross-validated performance
- Focusing on conclusions robust across methods

## Limitations

### Limitations of This Benchmark

1. **Simulated data**: Real biological data may have complexities not captured by our DGPs

2. **Method implementations**: Results reflect specific implementations and tuning choices; alternative implementations may perform differently

3. **Metric choice**: We focused on ATE estimation; other estimands (ATT, CATE) may show different patterns

4. **Computational environment**: Timing results depend on hardware and are provided for relative comparison only

5. **Limited scenarios**: While comprehensive, our scenarios cannot cover all possible data-generating processes

### Limitations of Observational Causal Inference

This benchmark evaluates methods under the assumption that unconfoundedness holds. In practice:

1. **Unverifiable assumption**: We can never verify that all confounders are measured

2. **Measurement error**: Covariates may be measured with error, violating SUTVA

3. **Time-varying confounding**: Our scenarios assume static treatment; longitudinal settings require specialized methods

4. **Selection bias**: Beyond confounding, selection effects may compromise causal inference

## Conclusions

This benchmark provides empirical evidence for method selection in high-dimensional causal inference. Key takeaways:

1. **Method choice matters**: Different methods have distinct strengths and weaknesses

2. **Context is crucial**: The best method depends on data characteristics and scientific goals

3. **Robustness checks are essential**: No method is universally superior; sensitivity analysis is critical

4. **cfomics provides a unified interface**: The package enables easy comparison of methods on the same data

We recommend that practitioners:
- Start with exploratory analysis to understand their data
- Apply multiple methods and compare results
- Conduct sensitivity analysis for unobserved confounding
- Report assumptions and limitations transparently
