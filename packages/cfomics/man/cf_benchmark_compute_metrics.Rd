% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/benchmark_metrics.R
\name{cf_benchmark_compute_metrics}
\alias{cf_benchmark_compute_metrics}
\title{Compute benchmark metrics for causal inference evaluation}
\usage{
cf_benchmark_compute_metrics(ate_hat, ite_hat, summary_hat = NULL, truth)
}
\arguments{
\item{ate_hat}{Numeric scalar, estimated average treatment effect}

\item{ite_hat}{Numeric vector, estimated individual treatment effects}

\item{summary_hat}{List (optional), summary statistics from predict(type="summary")
containing ate_ci_lower and ate_ci_upper for coverage calculation}

\item{truth}{List containing true values:
\itemize{
  \item ate_true: numeric scalar, true ATE
  \item ite_true: numeric vector, true ITEs
}}
}
\value{
A named list with:
  \itemize{
    \item bias_ate: ATE bias (ate_hat - ate_true)
    \item abs_bias_ate: Absolute ATE bias
    \item squared_error_ate: Squared error of ATE (bias^2). Note: This is
      the squared error for a single estimate. True MSE requires averaging
      over replications at the analysis stage.
    \item pehe: Precision in Estimation of Heterogeneous Effect
      (sqrt(mean((ite_hat - ite_true)^2)))
    \item coverage_ate: 0/1 indicator if true ATE is within CI (NA if no CI)
    \item ci_len_ate: Length of confidence interval (NA if no CI)
  }
}
\description{
This function computes evaluation metrics comparing estimated treatment
effects against known true values from simulation data.
}
